{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c548a60c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:47:46.808619Z",
     "iopub.status.busy": "2024-10-20T00:47:46.808196Z",
     "iopub.status.idle": "2024-10-20T00:47:50.806345Z",
     "shell.execute_reply": "2024-10-20T00:47:50.805324Z"
    },
    "papermill": {
     "duration": 4.01265,
     "end_time": "2024-10-20T00:47:50.809175",
     "exception": false,
     "start_time": "2024-10-20T00:47:46.796525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor, early_stopping, log_evaluation\n",
    "from catboost import  CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from xgboost import XGBRegressor, XGBClassifier, callback\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b603d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_now = datetime.datetime.now()\n",
    "run_postfix = dt_now.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b2ed92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:47:50.832620Z",
     "iopub.status.busy": "2024-10-20T00:47:50.831467Z",
     "iopub.status.idle": "2024-10-20T00:47:50.837672Z",
     "shell.execute_reply": "2024-10-20T00:47:50.836562Z"
    },
    "papermill": {
     "duration": 0.020158,
     "end_time": "2024-10-20T00:47:50.840043",
     "exception": false,
     "start_time": "2024-10-20T00:47:50.819885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT            = Path(\"../data\")\n",
    "\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n",
    "\n",
    "TARGET = 'target'\n",
    "EVAL = True\n",
    "EXPERIMENT_NAME = \"Home_Credit_2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5fc7d82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:47:50.863081Z",
     "iopub.status.busy": "2024-10-20T00:47:50.862172Z",
     "iopub.status.idle": "2024-10-20T00:47:50.898206Z",
     "shell.execute_reply": "2024-10-20T00:47:50.897114Z"
    },
    "papermill": {
     "duration": 0.050623,
     "end_time": "2024-10-20T00:47:50.900917",
     "exception": false,
     "start_time": "2024-10-20T00:47:50.850294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Common_LGB_Modelling:\n",
    "    \"\"\"\n",
    "        Train and test data should contain the same selected features for ML models.\n",
    "        Train, test data and target should be the same data type. (Pandas or Numpy)\n",
    "    \"\"\"\n",
    "    def __init__(self, config, model_class):\n",
    "        self.config = config\n",
    "        self.model_class = model_class\n",
    "    \n",
    "    def train(self, x_tr, y_tr):\n",
    "        \n",
    "        model = self.model_class(**self.config[\"params\"])\n",
    "        model.fit(x_tr, y_tr)\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    def train_and_valid(self, x_tr, y_tr, x_val, y_val):\n",
    "        \n",
    "        callbacks = [\n",
    "                early_stopping(stopping_rounds=self.config[\"es_round\"],\n",
    "                                   first_metric_only = True), \n",
    "                log_evaluation(self.config[\"verbose_eval\"])\n",
    "            ]\n",
    "            \n",
    "        model = self.model_class(**self.config[\"params\"])\n",
    "        model = model.fit(x_tr, y_tr, \n",
    "                          eval_set=[(x_val, y_val)], \n",
    "                          callbacks = callbacks)\n",
    "        valid_pred = model.predict(x_val)\n",
    "    \n",
    "        return model, valid_pred\n",
    "        \n",
    "    def test(self, models, test):\n",
    "        test_pred = [model.predict(test) for model in models]\n",
    "        test_pred = np.mean(test_pred, axis=0)\n",
    "        return test_pred\n",
    "    \n",
    "    def test_by_batch(self, models, test, batch_size):\n",
    "        test_pred_all = []\n",
    "        for idx in range(0, len(test), batch_size):\n",
    "            test_pred_batch = [model.predict(test.iloc[idx:idx+batch_size]) for model in models]\n",
    "            test_pred_batch = np.mean(test_pred_batch, axis=0)\n",
    "            test_pred_all.append(test_pred_batch)\n",
    "        return np.concatenate(test_pred_all)\n",
    "    \n",
    "    def numpy_test_by_batch(self, models, test, batch_size):\n",
    "        test_pred_all = []\n",
    "        for idx in range(0, len(test), batch_size):\n",
    "            test_pred_batch = [model.predict(test[idx:idx+batch_size]) for model in models]\n",
    "            test_pred_batch = np.mean(test_pred_batch, axis=0)\n",
    "            test_pred_all.append(test_pred_batch)\n",
    "        return np.concatenate(test_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "358100ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Common_CB_Modelling:\n",
    "    \"\"\"\n",
    "        Train and test data should contain the same selected features for ML models.\n",
    "        Train, test data and target should be the same data type. (Pandas or Numpy)\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self, x_tr, y_tr):\n",
    "        \n",
    "        train_pool = Pool(data=x_tr,\n",
    "                          label=y_tr,\n",
    "                          cat_features=self.config[\"cat_features\"])\n",
    "                \n",
    "        if self.config[\"task_type\"] == \"classification\":\n",
    "            model = CatBoostClassifier(**self.config[\"params\"])\n",
    "\n",
    "        elif self.config[\"task_type\"]:\n",
    "            model = CatBoostRegressor(**self.config[\"params\"])\n",
    "        model.fit(train_pool)\n",
    "            \n",
    "        return model\n",
    "\n",
    "    \n",
    "    def train_and_valid(self,  x_tr, y_tr, x_val, y_val):\n",
    "        \n",
    "        train_pool = Pool(data=x_tr,\n",
    "                          label=y_tr,\n",
    "                          cat_features=self.config[\"cat_features\"])\n",
    "        \n",
    "        valid_pool = Pool(data=x_val,\n",
    "                          label=y_val,\n",
    "                        cat_features=self.config[\"cat_features\"])\n",
    "                \n",
    "        if self.config[\"task_type\"] == \"classification\":\n",
    "            model = CatBoostClassifier(**self.config[\"params\"])\n",
    "            model.fit(train_pool,\n",
    "                      eval_set=[valid_pool], \n",
    "                      early_stopping_rounds=self.config[\"es_round\"],\n",
    "                      verbose_eval = self.config[\"verbose_eval\"])\n",
    "            valid_pred = model.predict_proba(x_val)[:,1]\n",
    "        elif self.config[\"task_type\"]:\n",
    "            model = CatBoostRegressor(**self.config[\"params\"])\n",
    "            model.fit(train_pool,\n",
    "                      eval_set=[valid_pool], \n",
    "                      early_stopping_rounds=self.config[\"es_round\"], \n",
    "                      verbose_eval = self.config[\"verbose_eval\"])\n",
    "            valid_pred = model.predict(x_val)\n",
    "            \n",
    "        return model, valid_pred\n",
    "    \n",
    "    def test(self, models, test):\n",
    "        if self.config[\"task_type\"] == \"classification\":\n",
    "            test_pred = [model.predict_proba(test)[:,1] for model in models]\n",
    "        else:\n",
    "            test_pred = [model.predict(test) for model in models]\n",
    "        test_pred = np.mean(test_pred, axis=0)        \n",
    "        return test_pred\n",
    "    \n",
    "    def test_by_batch(self, models, test, batch_size):\n",
    "        test_pred_all = []\n",
    "        for idx in range(0, len(test), batch_size):\n",
    "            if self.config[\"task_type\"] == \"classification\":\n",
    "                test_pred_batch = [model.predict_proba(test.iloc[idx:idx+batch_size])[:,1] for model in models]\n",
    "            else:\n",
    "                test_pred_batch = [model.predict(test.iloc[idx:idx+batch_size]) for model in models]            \n",
    "            test_pred_batch = np.mean(test_pred_batch, axis=0)\n",
    "            test_pred_all.append(test_pred_batch)\n",
    "        return np.concatenate(test_pred_all)\n",
    "    \n",
    "    def numpy_test_by_batch(self, models, test, batch_size):\n",
    "        test_pred_all = []\n",
    "        for idx in range(0, len(test), batch_size):\n",
    "            if self.config[\"task_type\"] == \"classification\":\n",
    "                test_pred_batch = [model.predict_proba(test[idx:idx+batch_size])[:,1] for model in models]\n",
    "            else:\n",
    "                test_pred_batch = [model.predict(test[idx:idx+batch_size]) for model in models]            \n",
    "            test_pred_batch = np.mean(test_pred_batch, axis=0)\n",
    "            test_pred_all.append(test_pred_batch)\n",
    "        return np.concatenate(test_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3261a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Common_XGB_Modelling:\n",
    "    \"\"\"\n",
    "        Train and test data should contain the same selected features for ML models.\n",
    "        Train, test data and target should be the same data type. (Pandas or Numpy)\n",
    "    \"\"\"\n",
    "    def __init__(self, config, model_class):\n",
    "        self.config = config\n",
    "        self.model_class = model_class\n",
    "    \n",
    "    def train_and_valid(self, x_tr, y_tr, x_val, y_val):\n",
    "                \n",
    "        model = self.model_class(**self.config[\"params\"])\n",
    "        model.fit(x_tr, y_tr, eval_set=[(x_val, y_val)])\n",
    "        valid_pred = model.predict(x_val, iteration_range=(0, model.best_iteration))\n",
    "    \n",
    "        return model, valid_pred\n",
    "    \n",
    "    def test(self, models, test):\n",
    "        test_pred = [model.predict(test,  iteration_range=(0, model.best_iteration)) for model in models]\n",
    "        test_pred = np.mean(test_pred, axis=0)\n",
    "        return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab41c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:47:50.924670Z",
     "iopub.status.busy": "2024-10-20T00:47:50.924252Z",
     "iopub.status.idle": "2024-10-20T00:47:50.939832Z",
     "shell.execute_reply": "2024-10-20T00:47:50.938727Z"
    },
    "papermill": {
     "duration": 0.030781,
     "end_time": "2024-10-20T00:47:50.942187",
     "exception": false,
     "start_time": "2024-10-20T00:47:50.911406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d492b",
   "metadata": {
    "papermill": {
     "duration": 0.010208,
     "end_time": "2024-10-20T00:47:50.962632",
     "exception": false,
     "start_time": "2024-10-20T00:47:50.952424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "------- edit from here -------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1d027",
   "metadata": {
    "papermill": {
     "duration": 0.010105,
     "end_time": "2024-10-20T00:47:50.982970",
     "exception": false,
     "start_time": "2024-10-20T00:47:50.972865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# common fe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a42010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:47:51.006719Z",
     "iopub.status.busy": "2024-10-20T00:47:51.005929Z",
     "iopub.status.idle": "2024-10-20T00:47:51.021891Z",
     "shell.execute_reply": "2024-10-20T00:47:51.020727Z"
    },
    "papermill": {
     "duration": 0.030948,
     "end_time": "2024-10-20T00:47:51.024210",
     "exception": false,
     "start_time": "2024-10-20T00:47:50.993262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    @staticmethod\n",
    "    def set_table_dtypes(df): #Standardize the dtype.\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))            \n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def handle_dates(df): #Change the feature for D to the difference in days from date_decision.\n",
    "        for col in df.columns:\n",
    "            if (col[-1] in (\"D\",)) and ('count' not in col):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n",
    "                df = df.with_columns(pl.col(col).dt.total_days())\n",
    "                \n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_cols(df): #Remove those with an average is_null exceeding 0.95 and those that do not fall within the range 1 < nunique < 200.\n",
    "        drop_cols = []\n",
    "        for col in df.columns:\n",
    "            #if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "            #    isnull = df[col].is_null().mean()\n",
    "            #    if isnull > 0.95:\n",
    "            #        drop_cols.append(col)\n",
    "\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\", ]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "\n",
    "                if (freq == 1) | (freq > 10):#50 #len(df) * 0.20): # 95 # fe4 down at fq20\n",
    "                    drop_cols.append(col)\n",
    "            \n",
    "            # eliminate yaer, month feature\n",
    "            # 644\n",
    "            if (col[-1] not in [\"P\", \"A\", \"L\", \"M\"]) and (('month_' in col) or ('year_' in col)):# or ('num_group' in col):\n",
    "            # if (('month_' in col) or ('year_' in col)):# or ('num_group' in col):\n",
    "                drop_cols.append(col)\n",
    "\n",
    "        return drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b15dbe9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:47:51.047666Z",
     "iopub.status.busy": "2024-10-20T00:47:51.047198Z",
     "iopub.status.idle": "2024-10-20T00:47:51.110433Z",
     "shell.execute_reply": "2024-10-20T00:47:51.109304Z"
    },
    "papermill": {
     "duration": 0.078519,
     "end_time": "2024-10-20T00:47:51.113172",
     "exception": false,
     "start_time": "2024-10-20T00:47:51.034653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    @staticmethod\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "\n",
    "        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        expr_2 = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        # expr_3 = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n",
    "        # expr_3 = [pl.var(col).alias(f\"var_{col}\") for col in cols]+ [pl.sum(col).alias(f\"sum_{col}\") for col in cols]\n",
    "        # expr_3 = [pl.last(col).alias(f\"last_{col}\") for col in cols] #+ \\\n",
    "        #     [pl.first(col).alias(f\"first_{col}\") for col in cols] + \\\n",
    "        #     [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + \\\n",
    "        #     [pl.std(col).alias(f\"std_{col}\") for col in cols]\n",
    "        # expr_3 = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n",
    "\n",
    "        cols2 = [col for col in df.columns if col[-1] in (\"L\", \"A\")]\n",
    "        expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + \\\n",
    "                 [pl.std(col).alias(f\"std_{col}\") for col in cols2] + \\\n",
    "                 [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + \\\n",
    "                 [pl.median(col).alias(f\"median_{col}\") for col in cols2] # + \\\n",
    "            # [pl.first(col).alias(f\"first_{col}\") for col in cols2] + [pl.last(col).alias(f\"last_{col}\") for col in cols2]\n",
    "        \n",
    "        # BAD\n",
    "        # cols3 = [col for col in df.columns if col[-1] in (\"A\")]\n",
    "        # expr_4 = [pl.col(col).fill_null(strategy=\"zero\").apply(lambda x: x.max() - x.min()).alias(f\"max-min_gap_{col}\") \n",
    "        #           for col in cols3]\n",
    "        return expr_1 + expr_2 + expr_3 # + [pl.col(col).diff().last().alias(f\"diff-last_{col}\") for col in cols3] # + expr_4\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def bureau_a1(df):\n",
    "        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        expr_2 = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "\n",
    "        cols2 = [\n",
    "            # bad\n",
    "        'annualeffectiverate_199L', 'annualeffectiverate_63L',\n",
    "        'contractsum_5085717L', \n",
    "        'credlmt_230A', 'credlmt_935A',\n",
    "        # 'debtoutstand_525A', 'debtoverdue_47A', 'dpdmax_139P', 'dpdmax_757P',\n",
    "    #    'instlamount_768A', 'instlamount_852A',\n",
    "    #    'interestrate_508L', 'monthlyinstlamount_332A',\n",
    "    #    'monthlyinstlamount_674A', \n",
    "            # good?\n",
    "       'nominalrate_281L', 'nominalrate_498L',\n",
    "       'numberofcontrsvalue_258L', 'numberofcontrsvalue_358L',\n",
    "       'numberofinstls_229L', 'numberofinstls_320L',\n",
    "       'numberofoutstandinstls_520L', 'numberofoutstandinstls_59L',\n",
    "       'numberofoverdueinstlmax_1039L', 'numberofoverdueinstlmax_1151L',\n",
    "       'numberofoverdueinstls_725L', 'numberofoverdueinstls_834L',\n",
    "            # bad?\n",
    "    #    'outstandingamount_354A', 'outstandingamount_362A', 'overdueamount_31A',\n",
    "    #    'overdueamount_659A', 'overdueamountmax2_14A', 'overdueamountmax2_398A',\n",
    "    #    'overdueamountmax_155A', 'overdueamountmax_35A',\n",
    "        # bad ?\n",
    "    #    'periodicityofpmts_1102L', 'periodicityofpmts_837L',\n",
    "    #    'prolongationcount_1120L', 'prolongationcount_599L',\n",
    "        # 520?\n",
    "    #    'residualamount_488A', 'residualamount_856A', 'totalamount_6A',\n",
    "    #    'totalamount_996A', 'totaldebtoverduevalue_178A',\n",
    "    #    'totaldebtoverduevalue_718A', 'totaloutstanddebtvalue_39A',\n",
    "    #    'totaloutstanddebtvalue_668A',\n",
    "       ]\n",
    "\n",
    "        # .697\n",
    "        # expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + [pl.std(col).alias(f\"std_{col}\") for col in cols2]\n",
    "        \n",
    "        # .696\n",
    "        # expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2]\n",
    "\n",
    "        # .697\n",
    "        # expr_3 = [pl.std(col).alias(f\"std_{col}\") for col in cols2]\n",
    "        \n",
    "        # .6985\n",
    "        # expr_3 = [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n",
    "\n",
    "        # .696\n",
    "        # expr_3 = [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] \n",
    "\n",
    "        # .6981\n",
    "        # expr_3 = [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n",
    "\n",
    "        # .696\n",
    "        # expr_3 = [pl.first(col).alias(f\"first_{col}\") for col in cols2] + [pl.last(col).alias(f\"last_{col}\") for col in cols2] # + \\\n",
    "        \n",
    "        # .696\n",
    "        # expr_3 = [pl.std(col).alias(f\"std_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n",
    "\n",
    "        # .699\n",
    "        # expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + [pl.std(col).alias(f\"std_{col}\") for col in cols2] + \\\n",
    "        #     [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n",
    "\n",
    "        expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + [pl.std(col).alias(f\"std_{col}\") for col in cols2] + \\\n",
    "            [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2] + \\\n",
    "            [pl.first(col).alias(f\"first_{col}\") for col in cols2] # + [pl.last(col).alias(f\"last_{col}\") for col in cols2] # not applied\n",
    "        \n",
    "        \n",
    "\n",
    "        # expr_3 = [pl.col(col).fill_null(strategy=\"zero\").apply(lambda x: x.max() - x.min()).alias(f\"max-min_gap_depth2_{col}\") for col in cols2]\n",
    "        return expr_1 + expr_2 + expr_3    \n",
    "\n",
    "    @staticmethod\n",
    "    def deposit_exprs(df):\n",
    "        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] # + \\\n",
    "            # [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "            # [pl.mean(col).alias(f\"mean_{col}\") for col in cols] # + \\\n",
    "            # [pl.std(col).alias(f\"std_{col}\") for col in cols]  + \\\n",
    "             \n",
    "            # [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_2 = [pl.first('openingdate_857D').alias(f'first_openingdate_857D')] + [pl.last('openingdate_857D').alias(f'last_openingdate_857D')]\n",
    "        \n",
    "        return expr_1 # + expr_2 #+ expr_ngmax\n",
    "\n",
    "    @staticmethod\n",
    "    def debitcard_exprs(df):\n",
    "        # cols = [col for col in df.columns if (col[-1] in [\"A\"])]\n",
    "        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] \n",
    "            # [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + \\\n",
    "            # [pl.std(col).alias(f\"std_{col}\") for col in cols]\n",
    "        # expr_2 = [pl.first('openingdate_857D').alias(f'first_openingdate_857D')] + [pl.last('openingdate_857D').alias(f'last_openingdate_857D')]\n",
    "        \n",
    "        return expr_1 # + expr_2 #+ expr_ngmax\n",
    "        # return expr_1\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def person_expr(df):\n",
    "        cols1 = ['empl_employedtotal_800L', 'empl_employedfrom_271D', 'empl_industry_691L', \n",
    "                 'familystate_447L', 'incometype_1044T', 'sex_738L', 'housetype_905L', 'housingtype_772L',\n",
    "                 'isreference_387L', 'birth_259D', ]\n",
    "        # cols1 = [col for col in df.columns]\n",
    "        expr_1 = [pl.first(col).alias(f\"first_{col}\") for col in cols1]\n",
    "        \n",
    "        expr_2 = [pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"), \n",
    "                  pl.col(\"mainoccupationinc_384A\").filter(pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")]\n",
    "        \n",
    "        # No Effect ...\n",
    "        # cols = ['personindex_1023L', 'persontype_1072L', 'persontype_792L']\n",
    "        # expr_3 = [pl.col(col).last().alias(f\"last_{col}\") for col in cols] + [pl.col(col).drop_nulls().mean().alias(f\"mean_{col}\") for col in cols]\n",
    "\n",
    "        # cols2 = [col for col in df.columns if col not in cols1]\n",
    "        # expr_4 = [pl.max(col).alias(f\"max_{col}\") for col in cols2] + [pl.min(col).alias(f\"min_{col}\") for col in cols2] #  good at cv, bad at lb ?\n",
    "            # [pl.col(col).drop_nulls().last().alias(f\"last_{col}\") for col in cols2] + [pl.col(col).drop_nulls().first().alias(f\"first_{col}\") for col in cols2] # no effect\n",
    "\n",
    "        return expr_1 + expr_2 # + expr_4 # + expr_3\n",
    "    \n",
    "    @staticmethod\n",
    "    def person_2_expr(df):\n",
    "        # cols = [col for col in df.columns]\n",
    "        cols = ['empls_economicalst_849M', 'empls_employedfrom_796D', 'empls_employer_name_740M'] # + \\\n",
    "            # ['relatedpersons_role_762T', 'conts_role_79M']\n",
    "            # ['addres_district_368M', 'addres_role_871L', 'addres_zip_823M']\n",
    "\n",
    "        expr_1 = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_2 = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "\n",
    "        # BAD\n",
    "        # expr_ngc = [pl.count(\"num_group2\").alias(f\"count_num_group2\")]\n",
    "        # cols2 = [col for col in df.columns if (col in (\"num_group1\", \"num_group2\"))]\n",
    "        # expr_ngmax = [pl.min(col).alias(f\"min_{col}\") for col in cols2] + [pl.max(col).alias(f\"max_{col}\") for col in cols2]\n",
    "\n",
    "        # cols2 = [col for col in df.columns if col not in cols]\n",
    "        # # expr_3 = [pl.max(col).alias(f\"max_{col}\") for col in cols2] + [pl.min(col).alias(f\"min_{col}\") for col in cols2] # no effect\n",
    "        # expr_3 = [pl.col(col).drop_nulls().last().alias(f\"last_{col}\") for col in cols2] # no effect\n",
    "\n",
    "        return expr_1 + expr_2 # + expr_3# + expr_ngc \n",
    "\n",
    "    @staticmethod\n",
    "    def other_expr(df):\n",
    "        expr_1 = [pl.first(col).alias(f\"__other_{col}\") for col in df.columns if ('num_group' not in col) and (col != 'case_id')]\n",
    "        # cols1 = ['amtdepositbalance_4809441A', 'amtdepositincoming_4809444A', 'amtdepositoutgoing_4809442A']\n",
    "        # expr_1 = [pl.last(col).alias(f\"last_{col}\") for col in cols1]\n",
    "        # cols2 = ['amtdebitincoming_4809443A', 'amtdebitoutgoing_4809440A']\n",
    "        # expr_3 = [(pl.col('amtdebitincoming_4809443A') - pl.col('amtdebitoutgoing_4809440A')).alias('amtdebit_incoming-outgoing')]\n",
    "        return expr_1 # + expr_2 + expr_3\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def tax_a_exprs(df):\n",
    "        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] + \\\n",
    "            [pl.last(col).alias(f\"last_{col}\") for col in cols] + \\\n",
    "            [pl.first(col).alias(f\"first_{col}\") for col in cols] + \\\n",
    "            [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + \\\n",
    "            [pl.std(col).alias(f\"std_{col}\") for col in cols]\n",
    "        # expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', 'num_group1']] + \\\n",
    "        #     [pl.min(col).alias(f\"min_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', ]] + \\\n",
    "        #     [pl.mean(col).alias(f\"mean_{col}\") for col in ['amount_4527230A']] + \\\n",
    "        #     [pl.std(col).alias(f\"std_{col}\") for col in ['amount_4527230A']] + \\\n",
    "        #     [pl.last(col).alias(f\"last_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', 'name_4527232M']] + \\\n",
    "        #     [pl.first(col).alias(f\"first_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', 'name_4527232M']] # BAD?\n",
    "\n",
    "        expr_4 = [pl.col(col).fill_null(strategy=\"zero\").map_elements(lambda x: x.max() - x.min(), return_dtype=pl.Float32).alias(f\"max-min_gap_depth2_{col}\") for col in ['amount_4527230A']]\n",
    "\n",
    "        return expr_1 + expr_4\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def bureau_a2(df): # 122만\n",
    "        # cols = ['collater_valueofguarantee_1124L', 'pmts_dpd_1073P', 'pmts_overdue_1140A',]\n",
    "        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "\n",
    "        expr_1 = [pl.max(col).alias(f\"max_depth2_{col}\") for col in cols]\n",
    "        expr_2 = [pl.min(col).alias(f\"min_depth2_{col}\") for col in cols]\n",
    "        expr_3 = [pl.mean(col).alias(f\"mean_depth2_{col}\") for col in cols] + \\\n",
    "            [pl.std(col).alias(f\"std_{col}\") for col in cols]\n",
    "        # expr_ngs = [pl.max(col).alias(f\"max_{col}\") for col in ['num_group1', 'num_group2', ]]\n",
    "\n",
    "        expr_4 = [pl.col(col).fill_null(strategy=\"zero\").map_elements(lambda x: x.max() - x.min(), return_dtype=pl.Float32).alias(f\"max-min_gap_depth2_{col}\") for col in ['collater_valueofguarantee_1124L', 'pmts_dpd_1073P', 'pmts_overdue_1140A',]]\n",
    "\n",
    "        expr_ngc = [pl.count(\"num_group2\").alias(f\"count_depth2_a2_num_group2\")]\n",
    "\n",
    "        # expr_5 = [pl.last(col).alias(f\"last_{col}\") for col in cols] + \\\n",
    "        #     [pl.first(col).alias(f\"first_{col}\") for col in cols] + \\\n",
    "        #     [pl.std(col).alias(f\"std_{col}\") for col in cols]\n",
    "\n",
    "        return expr_1 + expr_2 + expr_3 + expr_4 + expr_ngc # + expr_5\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df)\n",
    "\n",
    "        return exprs\n",
    "    \n",
    "    # no use from here\n",
    "    @staticmethod\n",
    "    def applprev2_exprs(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" not in col]\n",
    "        # expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] \n",
    "        expr_2 = [pl.first(col).alias(f\"first_{col}\") for col in cols]#  + [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        return []#expr_2\n",
    "    \n",
    "    @staticmethod\n",
    "    def bureau_b1(df):  # 0.95 filterにかかるため未使用\n",
    "        # cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "\n",
    "        # expr_1 = [pl.max(col).alias(f\"bureau_b1_max_{col}\") for col in cols]\n",
    "        # expr_2 = [pl.min(col).alias(f\"bureau_b1_min_{col}\") for col in cols]\n",
    "\n",
    "        # return expr_1 + expr_2 #  + expr_3\n",
    "        return []\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def bureau_b2(df):  # 0.95filterにかかるため未使用\n",
    "        # cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n",
    "\n",
    "        # expr_1 = [pl.max(col).alias(f\"bureau_b2_max_{col}\") for col in cols]\n",
    "        # expr_2 = [pl.min(col).alias(f\"bureau_b2_min_{col}\") for col in cols]\n",
    "\n",
    "        # return expr_1 + expr_2 #  + expr_3\n",
    "        return []\n",
    "\n",
    "    \n",
    "def agg_by_case(path, df):\n",
    "    path = str(path)\n",
    "    if '_applprev_1' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "\n",
    "#     elif '_applprev_2' in path:\n",
    "#         df = df.group_by(\"case_id\").agg(Aggregator.applprev2_exprs(df))\n",
    "\n",
    "    elif '_credit_bureau_a_1' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.bureau_a1(df))\n",
    "\n",
    "    elif '_credit_bureau_b_1' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.bureau_b1(df))\n",
    "\n",
    "    elif '_deposit_1' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.deposit_exprs(df))\n",
    "    elif '_debitcard_1' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.debitcard_exprs(df))\n",
    "        \n",
    "    elif '_tax_registry_a' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.tax_a_exprs(df))\n",
    "    elif '_tax_registry_b' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "    elif '_tax_registry_c' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        \n",
    "    elif '_other_1' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.other_expr(df))\n",
    "    elif '_person_1' in path:\n",
    "        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.person_expr(df))\n",
    "    elif '_person_2' in path:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.person_2_expr(df))\n",
    "\n",
    "    elif '_credit_bureau_a_2' in path:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.bureau_a2(df))\n",
    "    elif '_credit_bureau_b_2' in path:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_file(path, depth=None): \n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    \n",
    "    if depth in [1, 2]:\n",
    "        df = agg_by_case(path, df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    print(regex_path)\n",
    "    chunks = []\n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = agg_by_case(path, df)\n",
    "        chunks.append(df)\n",
    "        \n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base.with_columns(\n",
    "            decision_month = pl.col(\"date_decision\").dt.month(),\n",
    "            decision_weekday = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "        \n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base\n",
    "\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    print(df_data.info())\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "        #cat_cols = [c for c in cat_cols if 'diff_' not in c]\n",
    "    \n",
    "    df_data[cat_cols] = df_data[cat_cols].fillna(\"Missing\").astype(\"category\")\n",
    "    \n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618d030",
   "metadata": {
    "papermill": {
     "duration": 0.010184,
     "end_time": "2024-10-20T00:47:51.134086",
     "exception": false,
     "start_time": "2024-10-20T00:47:51.123902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b765a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:47:51.157288Z",
     "iopub.status.busy": "2024-10-20T00:47:51.156068Z",
     "iopub.status.idle": "2024-10-20T00:52:17.972492Z",
     "shell.execute_reply": "2024-10-20T00:52:17.971287Z"
    },
    "papermill": {
     "duration": 266.831037,
     "end_time": "2024-10-20T00:52:17.975464",
     "exception": false,
     "start_time": "2024-10-20T00:47:51.144427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/parquet_files/train/train_static_0_*.parquet\n",
      "../data/parquet_files/train/train_applprev_1_*.parquet\n",
      "../data/parquet_files/train/train_credit_bureau_a_1_*.parquet\n",
      "../data/parquet_files/train/train_credit_bureau_a_2_*.parquet\n"
     ]
    }
   ],
   "source": [
    "train_data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_person_2.parquet\", 2),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce6dc46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:52:17.999831Z",
     "iopub.status.busy": "2024-10-20T00:52:17.999102Z",
     "iopub.status.idle": "2024-10-20T00:52:37.202319Z",
     "shell.execute_reply": "2024-10-20T00:52:37.201071Z"
    },
    "papermill": {
     "duration": 19.218331,
     "end_time": "2024-10-20T00:52:37.205211",
     "exception": false,
     "start_time": "2024-10-20T00:52:17.986880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_overall = feature_eng(**train_data_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc44939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:52:37.228788Z",
     "iopub.status.busy": "2024-10-20T00:52:37.228376Z",
     "iopub.status.idle": "2024-10-20T00:52:37.904304Z",
     "shell.execute_reply": "2024-10-20T00:52:37.903079Z"
    },
    "papermill": {
     "duration": 0.690684,
     "end_time": "2024-10-20T00:52:37.906840",
     "exception": false,
     "start_time": "2024-10-20T00:52:37.216156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train_data_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bece3a8",
   "metadata": {
    "papermill": {
     "duration": 0.010351,
     "end_time": "2024-10-20T00:52:38.597688",
     "exception": false,
     "start_time": "2024-10-20T00:52:38.587337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# post fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d20c455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:52:38.659628Z",
     "iopub.status.busy": "2024-10-20T00:52:38.658337Z",
     "iopub.status.idle": "2024-10-20T00:53:47.825797Z",
     "shell.execute_reply": "2024-10-20T00:53:47.824319Z"
    },
    "papermill": {
     "duration": 69.18179,
     "end_time": "2024-10-20T00:53:47.828257",
     "exception": false,
     "start_time": "2024-10-20T00:52:38.646467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1526659 entries, 0 to 1526658\n",
      "Columns: 817 entries, case_id to last_empls_employer_name_740M\n",
      "dtypes: bool(1), float32(4), float64(660), int64(4), int8(2), object(146)\n",
      "memory usage: 9.2+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1526659 entries, 0 to 1526658\n",
      "Columns: 817 entries, case_id to last_empls_employer_name_740M\n",
      "dtypes: bool(1), category(146), float32(4), float64(660), int64(4), int8(2)\n",
      "memory usage: 7.9 GB\n"
     ]
    }
   ],
   "source": [
    "train_overall, str_features = to_pandas(train_overall)\n",
    "train_overall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0081aecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 8060.49 MB\n",
      "Memory usage after optimization is: 2986.56 MB\n",
      "Decreased by 62.9%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1526659 entries, 0 to 1526658\n",
      "Columns: 817 entries, case_id to last_empls_employer_name_740M\n",
      "dtypes: category(146), float16(416), float32(247), float64(2), int16(1), int32(1), int8(4)\n",
      "memory usage: 2.9 GB\n"
     ]
    }
   ],
   "source": [
    "train_overall = reduce_mem_usage(train_overall)\n",
    "train_overall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd76309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:53:48.518402Z",
     "iopub.status.busy": "2024-10-20T00:53:48.518036Z",
     "iopub.status.idle": "2024-10-20T00:53:57.192113Z",
     "shell.execute_reply": "2024-10-20T00:53:57.190952Z"
    },
    "papermill": {
     "duration": 8.690737,
     "end_time": "2024-10-20T00:53:57.196191",
     "exception": false,
     "start_time": "2024-10-20T00:53:48.505454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_cols = str_features[2:] #train_overall.pipe(Pipeline.filter_cols)\n",
    "train_overall = train_overall.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5939af98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:53:57.223275Z",
     "iopub.status.busy": "2024-10-20T00:53:57.222604Z",
     "iopub.status.idle": "2024-10-20T00:53:57.231420Z",
     "shell.execute_reply": "2024-10-20T00:53:57.230340Z"
    },
    "papermill": {
     "duration": 0.025386,
     "end_time": "2024-10-20T00:53:57.234657",
     "exception": false,
     "start_time": "2024-10-20T00:53:57.209271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_features = sorted([i for i in train_overall.columns if i not in [\"case_id\", \"MONTH\", \"WEEK_NUM\", \"target\"]])\n",
    "selected_cat_features = [col for i, col in enumerate(selected_features) if col in str_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31828a1",
   "metadata": {
    "papermill": {
     "duration": 0.011202,
     "end_time": "2024-10-20T00:53:57.257568",
     "exception": false,
     "start_time": "2024-10-20T00:53:57.246366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "369ab07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:53:57.282746Z",
     "iopub.status.busy": "2024-10-20T00:53:57.282365Z",
     "iopub.status.idle": "2024-10-20T00:53:57.290712Z",
     "shell.execute_reply": "2024-10-20T00:53:57.289565Z"
    },
    "papermill": {
     "duration": 0.023639,
     "end_time": "2024-10-20T00:53:57.293051",
     "exception": false,
     "start_time": "2024-10-20T00:53:57.269412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_config = {    \n",
    "        \"es_round\" : 20,\n",
    "        \"verbose_eval\": 100,\n",
    "        \"params\" : {\n",
    "            'objective': 'binary', \n",
    "            \"metric\": \"auc\",\n",
    "            \"n_estimators\": 100,#00,\n",
    "            'learning_rate': 0.02,\n",
    "            'scale_pos_weight': 10,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'verbose': -1,\n",
    "            'seed': 42,\n",
    "            'num_leaves': 64, \n",
    "            \"reg_alpha\": 0.1,\n",
    "            \"reg_lambda\": 10,\n",
    "            \"cat_smooth\": 20,\n",
    "            \"device\": \"gpu\",\n",
    "        },   \n",
    "    }\n",
    "xgb_config = {\n",
    "        \"params\" : {\n",
    "            \"n_estimators\" : 10,\n",
    "            'objective': \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"importance_type\": \"gain\",\n",
    "            \"enable_categorical\": True,\n",
    "            'learning_rate': 0.02,\n",
    "            'scale_pos_weight': 10,\n",
    "            'booster': 'gbtree',\n",
    "            'verbosity': 0,\n",
    "            'seed': 42,\n",
    "            \"reg_alpha\": 0.1,\n",
    "            \"reg_lambda\": 10,\n",
    "            \"device\": \"gpu\",\n",
    "            \"early_stopping_rounds\": 10,\n",
    "            \"verbose_eval\": 10,\n",
    "        },   \n",
    "}\n",
    "    \n",
    "cb_config = {\n",
    "        \"task_type\": \"classification\",\n",
    "        \"es_round\" : 20,\n",
    "        \"verbose_eval\": 500,\n",
    "        \"cat_features\": selected_cat_features,\n",
    "        \"params\" : { \n",
    "            'random_seed': 42,\n",
    "            \"learning_rate\": 0.04,\n",
    "            'use_best_model': True,\n",
    "            'iterations': 100,#00,\n",
    "            'reg_lambda': 10,\n",
    "            \"scale_pos_weight\": 10,\n",
    "            \"task_type\": \"GPU\",\n",
    "            'loss_function': 'Logloss',\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52538ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:53:57.318802Z",
     "iopub.status.busy": "2024-10-20T00:53:57.317979Z",
     "iopub.status.idle": "2024-10-20T00:53:57.322990Z",
     "shell.execute_reply": "2024-10-20T00:53:57.321871Z"
    },
    "papermill": {
     "duration": 0.02042,
     "end_time": "2024-10-20T00:53:57.325109",
     "exception": false,
     "start_time": "2024-10-20T00:53:57.304689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_modelling = Common_LGB_Modelling(lgb_config, LGBMClassifier)\n",
    "cb_modelling = Common_CB_Modelling(cb_config)\n",
    "xgb_modelling = Common_XGB_Modelling(xgb_config, XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21b42d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///tmp/working/mlruns/836281514613721981', creation_time=1730029393721, experiment_id='836281514613721981', last_update_time=1730029393721, lifecycle_stage='active', name='Home_Credit_2024', tags={}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e540b33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T00:53:57.373087Z",
     "iopub.status.busy": "2024-10-20T00:53:57.372711Z",
     "iopub.status.idle": "2024-10-20T00:53:57.444199Z",
     "shell.execute_reply": "2024-10-20T00:53:57.443295Z"
    },
    "papermill": {
     "duration": 0.087101,
     "end_time": "2024-10-20T00:53:57.446852",
     "exception": false,
     "start_time": "2024-10-20T00:53:57.359751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train_overall[TARGET].astype(np.float32).values\n",
    "train = read_file(TRAIN_DIR / \"train_base.parquet\")\n",
    "all_train_week_nums = train.unique(\"WEEK_NUM\").sort(\"WEEK_NUM\").select(\"WEEK_NUM\").to_numpy().reshape(-1)\n",
    "train_week_df = train.select(\"WEEK_NUM\").to_pandas()\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n",
    "tmp = train_overall[[\"WEEK_NUM\", \"target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895e2b6",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c42f888e",
   "metadata": {
    "papermill": {
     "duration": 0.018596,
     "end_time": "2024-10-20T03:23:32.408901",
     "exception": false,
     "start_time": "2024-10-20T03:23:32.390305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's auc: 0.831437\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.831437\n",
      "Evaluated only: auc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8e19756c4f4f5e88e7ff6af117bbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:23:55 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_1 at: http://mlflow:5000/#/experiments/836281514613721981/runs/de19e3162d7e45dca256b255d0a80f1a.\n",
      "2024/11/02 02:23:55 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 2\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's auc: 0.83378\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.83378\n",
      "Evaluated only: auc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c735bd08c34b48a2fd89525271a410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:24:29 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_2 at: http://mlflow:5000/#/experiments/836281514613721981/runs/e513540a9e2443a3a16ba7054b87cf0a.\n",
      "2024/11/02 02:24:29 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 3\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's auc: 0.837711\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.837711\n",
      "Evaluated only: auc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680f32cccca54df987226e9284669dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:25:04 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_3 at: http://mlflow:5000/#/experiments/836281514613721981/runs/38b26a16ad1c499fb089122261e85626.\n",
      "2024/11/02 02:25:04 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 4\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's auc: 0.835339\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.835339\n",
      "Evaluated only: auc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e53bc28e55472e81348c2c20113743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:25:40 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_4 at: http://mlflow:5000/#/experiments/836281514613721981/runs/0c940fb7280b42e89bf37a76bf8a39f6.\n",
      "2024/11/02 02:25:40 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 5\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's auc: 0.832092\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.832092\n",
      "Evaluated only: auc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05d603b991345499e0c7f4c0ff550d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:26:15 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_5 at: http://mlflow:5000/#/experiments/836281514613721981/runs/57203aff73f64f3992421148292a7fce.\n",
      "2024/11/02 02:26:15 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n",
      "2024/11/02 02:26:15 INFO mlflow.tracking._tracking_service.client: 🏃 View run lgb_2024-11-02T02:21:33.200150 at: http://mlflow:5000/#/experiments/836281514613721981/runs/5736c0b30650478f9f6e1948e5bb7be1.\n",
      "2024/11/02 02:26:15 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    }
   ],
   "source": [
    "mlflow.lightgbm.autolog(log_input_examples = True, log_datasets=False, silent = True)\n",
    "lgb_output =np.zeros(len(train_overall))\n",
    "\n",
    "with mlflow.start_run(run_name = \"lgb_\"+run_postfix) as run:\n",
    "    for fold, (tr_idx, val_idx) in enumerate(cv.split(train_overall, y_train, groups=train_week_df)):\n",
    "        print(\"Fold :\", fold + 1)\n",
    "        with mlflow.start_run(run_name='fold_'+str(fold+1), nested=True) as child_run:    \n",
    "            lgb_model, lgb_val_output = lgb_modelling.train_and_valid(train_overall.loc[tr_idx][selected_features], y_train[tr_idx],\n",
    "                                                              train_overall.loc[val_idx][selected_features], y_train[val_idx])\n",
    "        lgb_output[val_idx] = lgb_val_output\n",
    "        \n",
    "    mlflow.log_metric(\"overall score\", roc_auc_score(tmp[\"target\"].values, lgb_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61c3bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n",
      "0:\tlearn: 0.6748175\ttest: 0.6762859\tbest: 0.6762859 (0)\ttotal: 54ms\tremaining: 5.35s\n",
      "99:\tlearn: 0.4325537\ttest: 0.4502522\tbest: 0.4502522 (99)\ttotal: 5.35s\tremaining: 0us\n",
      "bestTest = 0.4502522288\n",
      "bestIteration = 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:36:55 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpkanas6a7/model, flavor: catboost). Fall back to return ['catboost==1.2.7']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/11/02 02:36:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "/opt/conda/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/02 02:36:55 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_1 at: http://mlflow:5000/#/experiments/836281514613721981/runs/be07e62c1d6d4b31b636d5fafb49a957.\n",
      "2024/11/02 02:36:55 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 2\n",
      "0:\tlearn: 0.6752945\ttest: 0.6749283\tbest: 0.6749283 (0)\ttotal: 53.2ms\tremaining: 5.27s\n",
      "99:\tlearn: 0.4367613\ttest: 0.4338011\tbest: 0.4338011 (99)\ttotal: 5.45s\tremaining: 0us\n",
      "bestTest = 0.4338010622\n",
      "bestIteration = 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:38:44 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpamx9yx3d/model, flavor: catboost). Fall back to return ['catboost==1.2.7']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/11/02 02:38:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "/opt/conda/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/02 02:38:44 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_2 at: http://mlflow:5000/#/experiments/836281514613721981/runs/c4a18a52d1684c298ecde3882cf26ac0.\n",
      "2024/11/02 02:38:44 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 3\n",
      "0:\tlearn: 0.6755158\ttest: 0.6750716\tbest: 0.6750716 (0)\ttotal: 51.8ms\tremaining: 5.13s\n",
      "99:\tlearn: 0.4370742\ttest: 0.4315417\tbest: 0.4315417 (99)\ttotal: 5.41s\tremaining: 0us\n",
      "bestTest = 0.4315417353\n",
      "bestIteration = 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:40:32 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpk2nbj8w5/model, flavor: catboost). Fall back to return ['catboost==1.2.7']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/11/02 02:40:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "/opt/conda/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/02 02:40:32 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_3 at: http://mlflow:5000/#/experiments/836281514613721981/runs/879bd0237f684ed0a7a739d82b7f52d7.\n",
      "2024/11/02 02:40:32 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 4\n",
      "0:\tlearn: 0.6751605\ttest: 0.6752585\tbest: 0.6752585 (0)\ttotal: 55.9ms\tremaining: 5.54s\n",
      "99:\tlearn: 0.4355594\ttest: 0.4380299\tbest: 0.4380299 (99)\ttotal: 5.56s\tremaining: 0us\n",
      "bestTest = 0.4380298725\n",
      "bestIteration = 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:42:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmphs6s17nn/model, flavor: catboost). Fall back to return ['catboost==1.2.7']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/11/02 02:42:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "/opt/conda/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/02 02:42:22 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_4 at: http://mlflow:5000/#/experiments/836281514613721981/runs/9c6a31204cd347a4897af54da4f3cd96.\n",
      "2024/11/02 02:42:22 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 5\n",
      "0:\tlearn: 0.6752273\ttest: 0.6747053\tbest: 0.6747053 (0)\ttotal: 52.9ms\tremaining: 5.24s\n",
      "99:\tlearn: 0.4360877\ttest: 0.4364281\tbest: 0.4364281 (99)\ttotal: 5.41s\tremaining: 0us\n",
      "bestTest = 0.436428061\n",
      "bestIteration = 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 02:44:10 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpz9vsvrer/model, flavor: catboost). Fall back to return ['catboost==1.2.7']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/11/02 02:44:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "/opt/conda/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/02 02:44:10 INFO mlflow.tracking._tracking_service.client: 🏃 View run fold_5 at: http://mlflow:5000/#/experiments/836281514613721981/runs/9418484785b84a27a9f9f5b0e5e317ca.\n",
      "2024/11/02 02:44:10 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n",
      "2024/11/02 02:44:10 INFO mlflow.tracking._tracking_service.client: 🏃 View run cb_2024-11-02T02:21:33.200150 at: http://mlflow:5000/#/experiments/836281514613721981/runs/901b38088617414d940f4b6cd3b44c7f.\n",
      "2024/11/02 02:44:10 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/836281514613721981.\n"
     ]
    }
   ],
   "source": [
    "cb_output =np.zeros(len(train_overall))\n",
    "with mlflow.start_run(run_name = \"cb_\"+run_postfix) as run:\n",
    "    for fold, (tr_idx, val_idx) in enumerate(cv.split(train_overall, y_train, groups=train_week_df)):\n",
    "        print(\"Fold :\", fold + 1)\n",
    "        with mlflow.start_run(run_name='fold_'+str(fold+1), nested=True) as child_run:    \n",
    "            cb_model, cb_val_output = cb_modelling.train_and_valid(\n",
    "                                                            train_overall.loc[tr_idx][selected_features], y_train[tr_idx],\n",
    "                                                            train_overall.loc[val_idx][selected_features], y_train[val_idx])\n",
    "            mlflow.catboost.log_model(cb_model, \"artifacts\")\n",
    "            mlflow.log_params(cb_config)\n",
    "            \n",
    "            dataset = mlflow.data.from_pandas(train_overall.head(1)[selected_features])\n",
    "            mlflow.log_input(dataset)\n",
    "        cb_output[val_idx] = cb_val_output\n",
    "    mlflow.log_metric(\"overall score\", roc_auc_score(tmp[\"target\"].values, cb_output)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53768893",
   "metadata": {},
   "source": [
    "mlflow.xgboost.autolog(log_input_examples = True, log_datasets=False, silent = True)\n",
    "xgb_output =np.zeros(len(train_overall))\n",
    "\n",
    "with mlflow.start_run(run_name = \"xgb_\"+run_postfix) as run:\n",
    "    for fold, (tr_idx, val_idx) in enumerate(cv.split(train_overall, y_train, groups=train_week_df)):\n",
    "        print(\"Fold :\", fold + 1)\n",
    "        with mlflow.start_run(run_name='fold_'+str(fold+1), nested=True) as child_run:    \n",
    "            xgb_model, xgb_val_output = treemodel.xgb_train_and_valid(train_overall.loc[tr_idx][selected_features], y_train[tr_idx],\n",
    "                                                              train_overall.loc[val_idx][selected_features], y_train[val_idx],\n",
    "                                                              config[\"lgb\"][\"params\"])\n",
    "        xgb_output[val_idx] = xgb_val_output\n",
    "        \n",
    "    mlflow.log_metric(\"overall score\", roc_auc_score(tmp[\"target\"].values, xgb_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f9711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    },
    {
     "datasetId": 4424545,
     "sourceId": 7600559,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9352.127713,
   "end_time": "2024-10-20T03:23:35.411978",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-20T00:47:43.284265",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
